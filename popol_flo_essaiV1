#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Aug 30 12:10:05 2019

@author: alflo
"""
#from urllib3 import urlopen
from urllib.request import urlopen
import bs4 as BeautifulSoup
import selenium
import re
import pandas as pd

#######creation data frame de collecte########

df_collecte= pd.DataFrame()
df_collecte = pd.DataFrame(columns =["intitulé", "lien_offre","type","contrat","durée",
                                     "temps de travail","localite","salaire",
                                     "site recruteur","date actualisé","reference",
                                     "contact mail","contact personne","experience",
                                     "site partenaire"])
i=1
########création de liste de recherche lieux et metier######  

liste_lieux=["24R","53R"]
liste_metier=["data","developpeur","python"]

########double boucle pour implémenter les critéres des listes ######

for l in range(len(liste_lieux)):
    lieux=liste_lieux[l]
    for m in range(len(liste_metier)):
        #print(liste_metier)
        mot_cle=liste_metier[m]
        #print(mot_cle)
        html='https://candidat.pole-emploi.fr/offres/recherche?lieux={}&motsCles={}&offresPartenaires=true&range=0-9&rayon=10&tri=0'.format(lieux,mot_cle)
        #print("adresse >>> ",html)
        
        
        #######création de la soupe ########## 
        
        html = urlopen(html).read()
        soup = BeautifulSoup.BeautifulSoup(html,features = "lxml")
        #print(soup)
        nb_offres=0
       
        
        for adresse_offre in soup.find_all("h2",attrs={"class":"media-heading"}):
            #print("adresse_annonce >>>" ,adresse_offre)
            nb_offres+=1
            #print("OFFRE BRUT >>>> ",adresse_offre)
            
#######extraction de l'intitule#######
            
            intitule=adresse_offre.text.replace('\n', '')
            

#########extraction de l'url de l'offre########
            
            #___________version regex______
            #print("INTITULE >>>> ",intitule)
            #ad=re. findall('(\/[\w]+\/[\w]+\/[\w]+\/[\w]+)',str(adresse_offre))
            #offre_emploi='https://candidat.pole-emploi.fr{}'.format(ad[0])
            #print("URL offre >>> ",offre_emploi)
            
            lien_offre="https://candidat.pole-emploi.fr{}".format(adresse_offre.find('a', class_ ='btn-reset')['href'])
            #print("LIEN OFFRE >>> ",lien_offre)
            
            lien=lien_offre
            
############soupe de l'annonce########            
            
            lien = urlopen(lien).read()
            soup = BeautifulSoup.BeautifulSoup(lien,features = "lxml")
            
#####dans l'offre extraction et separation du type du contrat et de la durée #########
            
                        
            type_contrat=soup.find_all("dd")
            type_contrat=type_contrat[0].text
            type_contrat=type_contrat.replace('\n',"-")
            type_contrat=type_contrat.replace('--',"/")
            type_contrat=type_contrat.replace('-',"")
            type_contrat=type_contrat.split("/")                
            contrat=type_contrat[0]
            type_=type_contrat[1]
            
            try:
                contrat=contrat.split("  ")
                duree=contrat[1]
                contrat=str(contrat[0])
                
                print(duree)
            except:
                duree=""
                contrat=type_contrat[0]
            
                print("contrat >>>> ",contrat ,"type_ >>>> ",type_)
            
##########dans l'offre extraction temps hebdomadaire#####
                        
            try:
                a=soup.find_all("dd",itemprop="workHours")
                #print(">>>",a)
                temps_hebdo=a[0].text
                #print(temps_hebdo)
            except:
                temps_hebdo=""
                #print(temps_hebdo)
                
###########dans l'offre extraction du salaire########
                
                
            try:
                r=soup.find_all("dd")
                liste_html=""
                for x in r:
                    liste_html+=str(x)
                id_salaire=(liste_html.index("Salaire"))+len("Salaire :")
                id_dd=liste_html.index("</dd><dd><a")
                salaire=liste_html[id_salaire:id_dd]
                salaire=re.findall('[\w]+',salaire)
                salaire=" ".join(salaire)
                print("$$$$$alaire>>>>",salaire)
            except:
                salaire=""
                
                

##########dans l'offre extraction dept-ville#####
                
            dept_ville=soup.find_all("span", itemprop="name")
            print("2>>>",dept_ville)
            dept_ville=dept_ville[0].text
            print(">>>>",dept_ville) 
            
###########dans l'offre extraction du site du recruteur#########

            try:
                site_recruteur=soup.find("a",class_='text-link')['href']
                print("site recruteur>>>",site_recruteur) 
                
                liste_contact=site_recruteur.split("/")
                print(liste_contact)
                
                if "offres"  in liste_contact:
                    print(">>> offres") 
                    site_recruteur=""
              
                          
            except:
                site_recruteur=""
            
###########dans l'offre extraction de la date d'actualisation au format XXXX-XX-XX ######
                
            date=soup.find_all("span",itemprop="datePosted")
            print(date)
            date_actualise=re.findall("([\d]{4}-[\d]{2}-[\d]{2})",str(date))
            date_actualise=date_actualise[0]
            print("date >>>> ",date_actualise)

#########dans l'offre extraction de la référence ###########            
            
            reference=soup.find_all("span",itemprop="value")
            reference=reference[0].text 
            print("reference >>>> ",reference)

###########extraction  des contacts personne et mail ########

            try:
                a=soup.find_all("div",class_="apply-block")
                a=(a[0].text)
                a=str(a)
                a=a.replace("Adresse électronique","")
                a = a.split()
                          
                contact=a[1:-2]
                contact_mail=a[-1]
                print(">>>> ",contact_mail)
                contact_personne=" ".join( contact )
                print(">>>> ",contact_personne)
            except:
                contact_mail=""
                contact_personne=""
                
############extraction de l'experience##########
                        
            a=soup.find_all("span",itemprop="experienceRequirements")
            experience=(a[0].text)
            print("experience >>>> ",experience)                 
                
                
                

############extraction de l'experience##########
                
            a=soup.find_all("span",itemprop="experienceRequirements")
            experience=(a[0].text)
            print("experience >>>> ",experience) 
            
############extraction du site de l'employeur en bas######

            try:
                a=soup.find_all("div", class_="media")
                a=(a[0].text)
                a=str(a)
                a = a.split()
                id_site=a.index('internet')
                site_recruteur=a[id_site+1]
                #id_site=site_recruteur
                print(id_site)            
            except:
                #site_recruteur=""
                id_site=""
                
############extraction du site du partenaire #######

            try:
                a=soup.find("ul", class_="partner-list"),["href"]               
                a=list(a)                
                a=a[0]
                a=str(a)                
                a=a.replace("href=","href= ")
                a=a.split()             
                id_site=a.index("href=")
                id_partenaire=a[id_site+1]
                id_partenaire=re.sub('["^\"","$\""]',"",id_partenaire)
                print(id_partenaire)
                #id_site=id_partenaire
            except: 
                id_partenaire=""
                #id_site:""
               
#########remplissage de la data frame df_collecte####### 
            
            df_collecte.loc[i] = [intitule, lien_offre,type_,contrat,duree,temps_hebdo,
                           dept_ville,salaire,site_recruteur,date_actualise,
                           reference,contact_mail,contact_personne,experience,
                           id_partenaire]
            


            
#########comptage des offres#####            
            
            i+=1
print("nb_offres>>>>",i)            
            
            
            
            
            
            